{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Example project (starter code): Generate a simple python word game to teach middle schoolers about history\n",
        "\n",
        "#PLEASE MAKE YOUR COPY OF THIS NOTEBOOK. Go to File > Save a copy in Drive\n",
        "\n",
        "##1.1 Target age group\n",
        "Middle school students (grades 6,7&8).\n",
        "##1.2 Content\n",
        "We scanned history curricula for middle school students, and listed the following\n",
        "##1.3 Teaching method\n",
        "Word-based game. An AI chatbot picks a secret figure, event or place in history. By asking it the right questions, students need to figure out what it is Through this fun interactive game, we can quench students’ curiosity and make history learning fun.\n",
        "##1.4 Project rationale\n",
        "In schools, world history is typically taught in a one-way linear fashion with the instructor delivering subject material to students who are meant to retain that knowledge. This makes little space for students’ curiosity. What if we can make history learning more playful and fun, while also encouraging students’ curiosity about historical figures, events & places. In this project, we make a word game, where students ask questions to an AI chatbot about a secret figure, event or place, and based on the chatbot’s response, try to guess what the secret figure, event or place is.\n"
      ],
      "metadata": {
        "id": "chBsWA-FS9_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first make a list of historical figures, places and events relevant for the target age. We used publicly available middle school curricula to make these lists.  The bot has access to a vast amount of information, you have vast choice in what fugures to include here.   Similarly for places and events."
      ],
      "metadata": {
        "id": "nFsrXSC7TU2s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXslKCQFRXqd"
      },
      "outputs": [],
      "source": [
        "#@title String fields\n",
        "\n",
        "targetage = 'high school' #@param {type:\"string\"}\n",
        "figures = ['Aristotle', 'Cleopatra', 'Genghis Khan', 'Joan of Arc', 'Leonardo da Vinci', 'William Shakespeare', 'Isaac Newton', 'Catherine the Great', 'Wolfgang Amadeus Mozart', 'Abraham Lincoln', 'Charles Darwin', 'Marie Curie', 'Albert Einstein', 'Nelson Mandela', 'Winston Churchill', 'Martin Luther King Jr.', 'Margaret Thatcher', 'Frida Kahlo', 'Napoleon Bonaparte', 'Queen Elizabeth I', 'Vincent van Gogh', 'Mahatma Gandhi', 'Rosa Parks', 'Pablo Picasso', 'Amelia Earhart', 'Orville Wright', 'Wilbur Wright', 'Mother Teresa', 'Walt Disney', 'Steve Jobs', 'Nikola Tesla', 'Mao Zedong', 'Franklin D. Roosevelt', 'Marilyn Monroe', 'Malcolm X', 'Katherine Johnson', 'Jane Goodall', 'Neil Armstrong', 'Elvis Presley', 'Queen Victoria']\n",
        "# You can add more figures in the line above.   Also add places and events in the lines below.\n",
        "places =  ['Random', 'Add more']\n",
        "event = ['Random', 'Add more']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SEZGCFrFdZzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's start making our word game. The first game step that students would take is pick if they want to play for figures, places or event"
      ],
      "metadata": {
        "id": "wyIoYHqrTiXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title String fields\n",
        "gameType = 'figures' #@param ['figures', 'places', 'event']"
      ],
      "metadata": {
        "id": "b0O65g0QUJmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the chatbot would randomly choose one of the items in your chosen list. Do not let the player know which entity was selected."
      ],
      "metadata": {
        "id": "VpnUl8aaUVlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "secret = random.choice(figures)\n",
        "# print(secret)"
      ],
      "metadata": {
        "id": "hiDyl2Qo4gs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now empower our chatbot with knowledge about the chosen entity. We will use GPT-4 to do that. First, let's install and import the OpanAI API.\n"
      ],
      "metadata": {
        "id": "woqgN1yzUOqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only required once.\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezsjntFJ6urh",
        "outputId": "3fc6a27b-b105-4da9-a807-043682c80cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Replace this with your openai key\n",
        "openai.api_key = ''"
      ],
      "metadata": {
        "id": "18jt7G0W6zkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now design a block for the player to ask questions to the chatbot. Think of what the rules are for the player to ask questions?\n",
        "\n",
        "Rules:\n",
        "\n",
        "\n",
        "*   You can ask any questions about the secret character / place / event. Eg. When were they born? What are they known for? What are they good at?\n",
        "*   You cannot directly ask the name of the character\n",
        "You can return to this block and ask as many questions as you would like! ✈\n",
        "\n"
      ],
      "metadata": {
        "id": "hLGjfTfk7tlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Player can enter their question here\n",
        "question = 'Where did she live?' #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "0m0jjhCW7sdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h5QkOra9dtiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's empower our AI bot with knowledge about the secret character / place / event. We will use the GPT model \"text-davinci-003\" to accomplish this. We will engineer our prompt to create the desirable chatbot response. We also want to double check that the AI chatbot doesn't accidentally say the name. So let's check for that. This will also check for if the player cheats by directly asking the name of the hidden secret."
      ],
      "metadata": {
        "id": "gOIgSnWk8oMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "botResponse = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Answer this question about the following person. Make it a short answer. Person: \" + secret + \". Question: \" + question + \"Do not include the person's name, only refer by pronoun\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=120,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.8,\n",
        "  presence_penalty=0.0,\n",
        ")\n",
        "\n",
        "botResponse = botResponse[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "#check if the response contains the secret and replace it with the word \"character\"\n",
        "if secret in botResponse:\n",
        "  botResponse = botResponse.replace(secret, \"Character\")\n",
        "\n",
        "print (botResponse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7hknrFj68jS",
        "outputId": "ee8fb4a9-f2a5-470f-c71f-679779422b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She lived in Russia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the player makes a guess, we check whether it matches the secret. If not, we ask them to try again."
      ],
      "metadata": {
        "id": "0QXiAohaBH_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install colorama to print the game responses in color. This is not required to run the game,\n",
        "!pip install colorama\n",
        "#install autocorrect to make space for spelling errors\n",
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCo16nPoFHp3",
        "outputId": "02f84d66-e6ee-4f4b-f325-9fb2a4eb3ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622363 sha256=c7846c2e575faf992c002486daf9813d0a252b43a091e9bb4ada68f330a909e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colorama import Fore\n",
        "\n",
        "from autocorrect import Speller\n",
        "spell = Speller(lang='en')\n",
        "\n",
        "guess = 'William Shakespeare' #@param {type:\"string\"}\n",
        "\n",
        "#we use upper to check for response in a case insensitive manner\n",
        "if guess.upper() == secret.upper():\n",
        "  print(Fore.GREEN + \"You got it! You're a history expert.\")\n",
        "\n",
        "#check for spelling mistakes\n",
        "elif spell(guess).upper() == secret.upper():\n",
        "  print(Fore.RED + \"You almost got it. Check your spelling!\")\n",
        "\n",
        "#ask them to try again if they are incorrect\n",
        "else:\n",
        "  print(Fore.RED + \"Oops, that is not correct. Let's try again!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU9tB1zuBHHF",
        "outputId": "81e7f998-33cd-4b73-f930-f91c3455321b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mOops, that is not correct. Let's try again!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer is here,\n",
        "\n",
        "print(secret)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eED6fn2U1Hc",
        "outputId": "e7cbfae1-7544-4571-cc25-7b38ecb0f7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Catherine the Great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAGvacdYp9zO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}